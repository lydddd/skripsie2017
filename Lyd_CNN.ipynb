{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import PIL\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/gpu:0']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54305\n",
      "0   /home/p2/skripsie/data/Apple___Apple_scab\n",
      "1   /home/p2/skripsie/data/Apple___Black_rot\n",
      "2   /home/p2/skripsie/data/Apple___Cedar_apple_rust\n",
      "3   /home/p2/skripsie/data/Apple___healthy\n",
      "4   /home/p2/skripsie/data/Blueberry___healthy\n",
      "5   /home/p2/skripsie/data/Cherry_(including_sour)___healthy\n",
      "6   /home/p2/skripsie/data/Cherry_(including_sour)___Powdery_mildew\n",
      "7   /home/p2/skripsie/data/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      "8   /home/p2/skripsie/data/Corn_(maize)___Common_rust_\n",
      "9   /home/p2/skripsie/data/Corn_(maize)___healthy\n",
      "10   /home/p2/skripsie/data/Corn_(maize)___Northern_Leaf_Blight\n",
      "11   /home/p2/skripsie/data/Grape___Black_rot\n",
      "12   /home/p2/skripsie/data/Grape___Esca_(Black_Measles)\n",
      "13   /home/p2/skripsie/data/Grape___healthy\n",
      "14   /home/p2/skripsie/data/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "15   /home/p2/skripsie/data/Orange___Haunglongbing_(Citrus_greening)\n",
      "16   /home/p2/skripsie/data/Peach___Bacterial_spot\n",
      "17   /home/p2/skripsie/data/Peach___healthy\n",
      "18   /home/p2/skripsie/data/Pepper,_bell___Bacterial_spot\n",
      "19   /home/p2/skripsie/data/Pepper,_bell___healthy\n",
      "20   /home/p2/skripsie/data/Potato___Early_blight\n",
      "21   /home/p2/skripsie/data/Potato___healthy\n",
      "22   /home/p2/skripsie/data/Potato___Late_blight\n",
      "23   /home/p2/skripsie/data/Raspberry___healthy\n",
      "24   /home/p2/skripsie/data/Soybean___healthy\n",
      "25   /home/p2/skripsie/data/Squash___Powdery_mildew\n",
      "26   /home/p2/skripsie/data/Strawberry___healthy\n",
      "27   /home/p2/skripsie/data/Strawberry___Leaf_scorch\n",
      "28   /home/p2/skripsie/data/Tomato___Bacterial_spot\n",
      "29   /home/p2/skripsie/data/Tomato___Early_blight\n",
      "30   /home/p2/skripsie/data/Tomato___healthy\n",
      "31   /home/p2/skripsie/data/Tomato___Late_blight\n",
      "32   /home/p2/skripsie/data/Tomato___Leaf_Mold\n",
      "33   /home/p2/skripsie/data/Tomato___Septoria_leaf_spot\n",
      "34   /home/p2/skripsie/data/Tomato___Spider_mites Two-spotted_spider_mite\n",
      "35   /home/p2/skripsie/data/Tomato___Target_Spot\n",
      "36   /home/p2/skripsie/data/Tomato___Tomato_mosaic_virus\n",
      "37   /home/p2/skripsie/data/Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "['Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy', 'Blueberry___healthy', 'Cherry_(including_sour)___healthy', 'Cherry_(including_sour)___Powdery_mildew', 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Grape___Black_rot', 'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight', 'Potato___healthy', 'Potato___Late_blight', 'Raspberry___healthy', 'Soybean___healthy', 'Squash___Powdery_mildew', 'Strawberry___healthy', 'Strawberry___Leaf_scorch', 'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy', 'Tomato___Late_blight', 'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Target_Spot', 'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus']\n",
      "54305\n",
      "(54305,)\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"/home/p2/skripsie/data\"\n",
    "nb_images = len(glob.glob(data_dir+\"/*/*.*\"))\n",
    "hold = 0\n",
    "image_size = 256\n",
    "test_percentage = .2\n",
    "\n",
    "print nb_images\n",
    "# 52803\n",
    "\n",
    "X = []\n",
    "# X.resize(nb_images)\n",
    "Y = []\n",
    "class_names = []\n",
    "# print X.shape\n",
    "\n",
    "#data folder structure\n",
    "#Dataset->[ABR->[ABR1]; AS->[AS1; AS2]]\n",
    "directory = data_dir + \"/*\"\n",
    "classes = glob.glob(directory)\n",
    "label = 0\n",
    "imgcount = 0\n",
    "for one_class in classes:\n",
    "    class_names.append(one_class.split('/')[-1])\n",
    "    imgs = glob.glob(one_class+'/*')\n",
    "    print label ,\" \", one_class\n",
    "    for img in imgs:\n",
    "        imgcount += 1\n",
    "#         im = Image.open(img)\n",
    "#         im_arr = np.array(im) # img = file path\n",
    "#         print img\n",
    "        X.append(img)\n",
    "        Y.append(label)\n",
    "    label += 1\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "# print Y\n",
    "print class_names\n",
    "print imgcount\n",
    "print np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/p2/skripsie/data/Apple___healthy/430fd7d8-9390-411c-b849-e421cf11f7a7___RS_HL 7314.JPG\n"
     ]
    }
   ],
   "source": [
    "print X[2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/p2/skripsie/data/Tomato___Tomato_Yellow_Leaf_Curl_Virus/fafa446d-bbd4-4fe2-a0a8-72472392548e___UF.GRC_YLCV_Lab 03233.JPG\n",
      "37\n",
      "10861\n",
      "(10861,)\n",
      "(43444,)\n",
      "(10861,)\n",
      "(43444,)\n"
     ]
    }
   ],
   "source": [
    "#Next up: shuffle data and split up into train and test sets.\n",
    "#shuffle\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "def shuffle_in_unison_scary(a, b):\n",
    "    rng_state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(rng_state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "# X, Y = unison_shuffled_copies(X, Y)\n",
    "shuffle_in_unison_scary(X, Y)\n",
    "\n",
    "\n",
    "print X[0]\n",
    "print Y[0]\n",
    "\n",
    "\n",
    "#split in train and test --> \n",
    "\n",
    "test_nr = (int)(test_percentage*nb_images)\n",
    "\n",
    "print test_nr\n",
    "X_train = X[:test_nr]\n",
    "X_test = X[test_nr:]\n",
    "Y_train = Y[:test_nr]\n",
    "Y_test = Y[test_nr:]\n",
    "\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print Y_train.shape\n",
    "print Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need:\n",
    "    batch_X and batch_Y train data\n",
    "    batch_X, batch_Y = next_batch(38*2) <-- function to get them\n",
    "    \n",
    "    replacement for this:\n",
    "    test_data={X:mnist.test.images, Y_:mnist.test.labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toImages(batchFiles):    \n",
    "    imgBatch = []\n",
    "    \n",
    "    for imgfile in batchFiles:\n",
    "        image = cv2.imread(imgfile)\n",
    "        image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "        image = image.astype(np.float32)\n",
    "        image = np.multiply(image, 1.0 / 255.0)\n",
    "        \n",
    "        imgBatch.append(image)\n",
    "    \n",
    "    imgBatch = np.array(imgBatch)\n",
    "#     print imgBatch.shape\n",
    "    return imgBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_Files = X_train[0 * 5:(0+1) * 5]\n",
    "batch_X = toImages(batch_Files)\n",
    "# print a\n",
    "# print b"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def next_batch(batchSize):\n",
    "    batchFiles = X[hold:hold+batchSize]\n",
    "    batchLabels = Y[hold:hold+batchSize]\n",
    "#     print batchFiles\n",
    "#     print batchLabels\n",
    "    imgBatch = []\n",
    "    \n",
    "    for imgfile in batchFiles:\n",
    "        image = cv2.imread(imgfile)\n",
    "        image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "        image = image.astype(np.float32)\n",
    "        image = np.multiply(image, 1.0 / 255.0)\n",
    "        \n",
    "        imgBatch.append(image)\n",
    "    \n",
    "    imgBatch = np.array(imgBatch)\n",
    "    hold += batchSize\n",
    "    print imgBatch.shape\n",
    "    return imgBatch, batchLabels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "TRAIN_DATASIZE,_,_,_ = X_train.shape\n",
    "PERIOD = TRAIN_DATASIZE/BATCH_SIZE #Number of iterations for each epoch\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    idxs = numpy.random.permutation(TRAIN_DATASIZE) #shuffled ordering\n",
    "    X_random = X_train[idxs]\n",
    "    Y_random = Y_train[idxs]\n",
    "    for i in range(PERIOD):\n",
    "        batch_X = X_random[i * BATCH_SIZE:(i+1) * BATCH_SIZE]\n",
    "        batch_Y = Y_random[i * BATCH_SIZE:(i+1) * BATCH_SIZE]\n",
    "        sess.run(train,feed_dict = {X: batch_X, Y:batch_Y})"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_size = 28\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "class_names = []\n",
    "#data folder structure\n",
    "#Dataset->[ABR->[ABR1]; AS->[AS1; AS2]]\n",
    "directory = \"data/*\"\n",
    "classes = glob.glob(directory)\n",
    "label = 0\n",
    "imgcount = 0\n",
    "for one_class in classes:\n",
    "    class_names.append(one_class.split('/')[1])\n",
    "    imgs = glob.glob(one_class+'/*')\n",
    "    print label ,\" \", one_class\n",
    "    for img in imgs:\n",
    "        image = cv2.imread(img)\n",
    "        image = cv2.resize(image, (image_size, image_size),0,0, cv2.INTER_LINEAR)\n",
    "        image = image.astype(np.float32)\n",
    "        image = np.multiply(image, 1.0 / 255.0)\n",
    "        \n",
    "        imgcount += 1\n",
    "        X.append(image)\n",
    "        Y.append(label)\n",
    "    label += 1\n",
    "    \n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "print Y\n",
    "print class_names\n",
    "print imgcount\n",
    "# print np.shape(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "class_names = []\n",
    "#data folder structure\n",
    "#Dataset->[ABR->[ABR1]; AS->[AS1; AS2]]\n",
    "directory = \"data/*\"\n",
    "classes = glob.glob(directory)\n",
    "label = 0\n",
    "imgcount = 0\n",
    "for one_class in classes:\n",
    "    class_names.append(one_class.split('/')[1])\n",
    "    imgs = glob.glob(one_class+'/*')\n",
    "    print label ,\" \", one_class\n",
    "    for img in imgs:\n",
    "        imgcount += 1\n",
    "        im = Image.open(img)\n",
    "        im_arr = np.array(im) # im_arr.shape: height x width x channel\n",
    "        X.append(im_arr)\n",
    "        Y.append(label)\n",
    "    label += 1\n",
    "# X = np.array(X)\n",
    "print Y\n",
    "print class_names\n",
    "print imgcount\n",
    "# print np.shape(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([])\n",
    "X.resize((54305, 256, 256, 3))\n",
    "Y = []\n",
    "class_names = []\n",
    "#data folder structure\n",
    "#Dataset->[ABR->[ABR1]; AS->[AS1; AS2]]\n",
    "directory = \"data/*\"\n",
    "classes = glob.glob(directory)\n",
    "label = 0\n",
    "# hold = 0\n",
    "imgcount = 0\n",
    "for one_class in classes:\n",
    "    class_names.append(one_class.split('/')[1])\n",
    "    imgs = glob.glob(one_class+'/*')\n",
    "    print label ,\" \", one_class\n",
    "    for img in imgs:        \n",
    "        im = Image.open(img)\n",
    "        im_arr = np.array(im) # im_arr.shape: height x width x channel\n",
    "#         print X.shape\n",
    "#         X.resize((imgcount, 256, 256, 3))\n",
    "#         print X.shape\n",
    "        X[imgcount:] = im_arr\n",
    "#         if (hold==0):\n",
    "#             X = np.array(im)\n",
    "#             hold = 1\n",
    "#         else: np.append(X) X.npappend(im_arr)\n",
    "        Y.append(label)\n",
    "        imgcount += 1\n",
    "    \n",
    "    label += 1\n",
    "# X = np.array(X)\n",
    "print Y\n",
    "print class_names\n",
    "print X.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "\n",
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Y = []\n",
    "class_names = []\n",
    "#data folder structure\n",
    "#Dataset->[ABR->[ABR1]; AS->[AS1; AS2]]\n",
    "directory = \"data/*\"\n",
    "classes = glob.glob(directory)\n",
    "label = 0\n",
    "imgcount = 0\n",
    "for one_class in classes:\n",
    "    class_names.append(one_class.split('/')[1])\n",
    "    imgs = glob.glob(one_class+'/*')\n",
    "    print label ,\" \", one_class\n",
    "    for img in imgs:\n",
    "        imgcount += 1\n",
    "        im = Image.open(img)\n",
    "        im_arr = np.array(im) # im_arr.shape: height x width x channel\n",
    "        X.append(im_arr)\n",
    "        Y.append(label)\n",
    "    label += 1\n",
    "# X = np.array(X)\n",
    "print Y\n",
    "print class_names\n",
    "print imgcount\n",
    "# print np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y2:  (?, 64, 64, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 16384 and 196 for 'MatMul' (op: 'MatMul') with input shapes: [?,16384], [196,1444].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-d7bbbb736dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# HIDDEN FULLY CONNECTED LAYER:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mYY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# First we need to flatten the volume\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mY3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mB3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Now compute the hidden output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Shape of Y3: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc\u001b[0m in \u001b[0;36mmatmul\u001b[0;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1843\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[0;32m-> 1844\u001b[0;31m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc\u001b[0m in \u001b[0;36m_mat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   1287\u001b[0m   \"\"\"\n\u001b[1;32m   1288\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[0;32m-> 1289\u001b[0;31m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[1;32m   1290\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/p2/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 16384 and 196 for 'MatMul' (op: 'MatMul') with input shapes: [?,16384], [196,1444]."
     ]
    }
   ],
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "NR_CLASSES = 38\n",
    "TRAIN_DATASIZE = nb_images\n",
    "PERIOD = TRAIN_DATASIZE/BATCH_SIZE #Number of iterations for each epoch\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 196606])   # A placeholder for the input image\n",
    "X_reshaped = tf.reshape(X, [-1, 256, 256, 3])   # TensorFlow's convolutional operation wants a \"volume\" \n",
    "\n",
    "layer_1_depth = 2   # How deep is layer 1?\n",
    "layer_2_depth = 4   # How deep is layer 2? \n",
    "filter_size = 5     # What size of filters do we want?\n",
    "\n",
    "# Create the parameters for layer 1\n",
    "W1 = tf.Variable(tf.truncated_normal([filter_size, filter_size, 3, layer_1_depth] ,stddev=0.1))\n",
    "B1 = tf.Variable(tf.ones([layer_1_depth])/NR_CLASSES)\n",
    "\n",
    "# Create the parameters for layer 2\n",
    "W2 = tf.Variable(tf.truncated_normal([filter_size, filter_size, layer_1_depth, layer_2_depth] ,stddev=0.1))\n",
    "B2 = tf.Variable(tf.ones([layer_2_depth])/NR_CLASSES)\n",
    "\n",
    "# CONVOLUTIONAL LAYER 1: \n",
    "Y1 = tf.nn.relu(tf.nn.conv2d(X_reshaped, W1, strides=[1, 1, 1, 1], padding='SAME') + B1)\n",
    "\n",
    "# POOLING \n",
    "pool = tf.nn.max_pool(Y1, ksize=[1, 2, 2, 1],\n",
    "                      strides=[1, 2, 2, 1], \n",
    "                      padding='SAME')\n",
    "\n",
    "# CONVOLUTIONAL LAYER 2\n",
    "Y2 = tf.nn.relu(tf.nn.conv2d(pool, W2, strides=[1, 2, 2, 1], padding='SAME') + B2)\n",
    "\n",
    "print \"Shape of Y2: \", Y2.get_shape()\n",
    "\n",
    "fully_connected_size = 1444\n",
    "\n",
    "# Create the parameters for the hidden fully connected layer\n",
    "W3 = tf.Variable(tf.truncated_normal([7*7*layer_2_depth, fully_connected_size] ,stddev=0.1))\n",
    "B3 = tf.Variable(tf.ones([fully_connected_size])/NR_CLASSES)\n",
    "\n",
    "# HIDDEN FULLY CONNECTED LAYER:\n",
    "YY = tf.contrib.layers.flatten(Y2)  # First we need to flatten the volume\n",
    "Y3 = tf.nn.relu(tf.matmul(YY, W3) + B3)  # Now compute the hidden output\n",
    "\n",
    "print \"Shape of Y3: \", Y3.get_shape()\n",
    "\n",
    "# Create the parameters of the final logits layer\n",
    "W4 = tf.Variable(tf.zeros([fully_connected_size, NR_CLASSES]))  \n",
    "B4 = tf.Variable(tf.zeros([NR_CLASSES]))\n",
    "\n",
    "# Compute the model predictions! \n",
    "logits = tf.matmul(Y3, W4) + B4   # Compute the logits\n",
    "Y = tf.nn.softmax(logits)     # Compute the model predictions\n",
    "\n",
    "# placeholder for correct answers\n",
    "Y_ = tf.placeholder(tf.float32, [None, NR_CLASSES])   \n",
    "\n",
    "# loss function\n",
    "cross_entropy = -tf.reduce_mean(Y_ * tf.log(Y))\n",
    "\n",
    "# % of correct answers found in batch\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.003)   # Now we try an Adam optimizer\n",
    "train_step = optimizer.minimize(cross_entropy)   # An op to minimise the cross entropy loss\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "avg_train_cost = 0.\n",
    "avg_train_accuracy = 0.\n",
    "avg_test_cost = 0.\n",
    "avg_test_accuracy = 0.\n",
    "\n",
    "###############################################################\n",
    "\n",
    "for e in range(EPOCH):\n",
    "    idxs = numpy.random.permutation(TRAIN_DATASIZE) #shuffled ordering\n",
    "    X_random = X_train[idxs]\n",
    "    Y_random = Y_train[idxs]\n",
    "    for i in range(PERIOD):   \n",
    "        batch_Y = Y_random[i * BATCH_SIZE:(i+1) * BATCH_SIZE]\n",
    "        batch_Files = X_random[i * BATCH_SIZE:(i+1) * BATCH_SIZE]\n",
    "        batch_X = toImages(batch_Files)\n",
    "        train_data = {X: batch_X, Y:batch_Y}\n",
    "        sess.run(train_step,feed_dict = train_data)\n",
    "\n",
    "###############################################################\n",
    "\n",
    "# num_steps = 5000\n",
    "\n",
    "# for i in range(num_steps):\n",
    "#     # load batch of images and correct answers\n",
    "#     batch_X, batch_Y = next_batch(38*2)\n",
    "#     train_data={X: batch_X, Y_: batch_Y}\n",
    "\n",
    "#     # train\n",
    "#     sess.run(train_step, feed_dict=train_data)\n",
    "\n",
    "   \n",
    "    \n",
    "###############################################################    \n",
    "     \n",
    "    # success ? add code to print it\n",
    "    a,c = sess.run([accuracy, cross_entropy], feed_dict=train_data)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print \"Step\", i, \"Current train cost and accuracy: \", c, a\n",
    "    \n",
    "    avg_train_cost += c\n",
    "    avg_train_accuracy += a\n",
    "    \n",
    "print(\"Completed Training\")\n",
    "\n",
    "avg_train_cost /= num_steps\n",
    "avg_train_accuracy /= num_steps\n",
    "\n",
    "print(\"Average train cost: \", avg_train_cost)\n",
    "print(\"Average train accuracy: \", avg_train_accuracy)\n",
    "\n",
    "\n",
    "# success on test data ?\n",
    "test_data={X:toImages(X_test), Y_:Y_test}\n",
    "a,c = sess.run([accuracy, cross_entropy], feed_dict=test_data)\n",
    "\n",
    "print(\"Test cost: \", c)\n",
    "print(\"Test accuracy: \", a)\n",
    "\n",
    "\n",
    "\n",
    "# need:\n",
    "#     batch_X and batch_Y train data\n",
    "#     batch_X, batch_Y = next_batch(38*2) <-- function to get them\n",
    "    \n",
    "#     replacement for this\n",
    "#     test_data={X:X_test, Y_:Y_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
